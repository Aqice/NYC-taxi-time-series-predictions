{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction May and June data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = pd.read_csv('cluster_0.csv', index_col=0)\n",
    "data_1 = pd.read_csv('cluster_1.csv', index_col=0)\n",
    "data_2 = pd.read_csv('cluster_2.csv', index_col=0)\n",
    "data_3 = pd.read_csv('cluster_3.csv', index_col=0)\n",
    "data_4 = pd.read_csv('cluster_4.csv', index_col=0)\n",
    "data_0 = data_0.set_index(pd.date_range('01/01/2016', periods=int(data_0.shape[0]), freq='H'))\n",
    "data_0.drop(['value_mean', 'value_std'], axis=1, inplace=True)\n",
    "data_0.columns = [str(int(i)+1) for i in list(data_0.columns)]\n",
    "data_1 = data_1.set_index(pd.date_range('01/01/2016', periods=int(data_1.shape[0]), freq='H'))\n",
    "data_1.drop(['value_mean', 'value_std'], axis=1, inplace=True)\n",
    "data_1.columns = [str(int(i)+1) for i in list(data_1.columns)]\n",
    "data_2 = data_2.set_index(pd.date_range('01/01/2016', periods=int(data_2.shape[0]), freq='H'))\n",
    "data_2.drop(['value_mean', 'value_std'], axis=1, inplace=True)\n",
    "data_2.columns = [str(int(i)+1) for i in list(data_2.columns)]\n",
    "data_3 = data_3.set_index(pd.date_range('01/01/2016', periods=int(data_3.shape[0]), freq='H'))\n",
    "data_3.drop(['value_mean', 'value_std'], axis=1, inplace=True)\n",
    "data_3.columns = [str(int(i)+1) for i in list(data_3.columns)]\n",
    "data_4 = data_4.set_index(pd.date_range('01/01/2016', periods=int(data_4.shape[0]), freq='H'))\n",
    "data_4.drop(['value_mean', 'value_std'], axis=1, inplace=True)\n",
    "data_4.columns = [str(int(i)+1) for i in list(data_4.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_regressive_features(series):\n",
    "    feature_df = pd.DataFrame(series).drop(pd.DataFrame(series).columns, axis=1) # df to store regressive features for every series\n",
    "    for i in range(1, 6):\n",
    "        feature_df['sin_value_{}'.format(i)] = np.sin(np.arange(series.shape[0]) * 2*np.pi * i/720)\n",
    "        feature_df['cos_value_{}'.format(i)] = np.cos(np.arange(series.shape[0]) * 2*np.pi * i/720)\n",
    "    feature_df['roll_12'.format(i)] = series.rolling(12).mean()\n",
    "    feature_df['roll_24'.format(i)] = series.rolling(24).mean()\n",
    "    feature_df['roll_96'.format(i)] = series.rolling(96).mean()\n",
    "    feature_df['roll_168'.format(i)] = series.rolling(168).mean()\n",
    "    isWeekend = lambda x: 1 if x in (5, 6) else 0\n",
    "    feature_df['is_weekend'] = [isWeekend(i) for i in feature_df.index.dayofweek]\n",
    "    feature_df['is_new_year'] = [(lambda x: 1 if (x[0]==1 & x[1]==1) else 0)(x) for x in zip(feature_df.index.day,\n",
    "                                                                                           feature_df.index.month)]\n",
    "    feature_df['is_martin_luther'] = [(lambda x: 1 if (x[0]==18 & x[1]==1) else 0)(x) for x in zip(feature_df.index.day,\n",
    "                                                                                           feature_df.index.month)]\n",
    "    feature_df['is_presidents_day'] = [(lambda x: 1 if (x[0]==15 & x[1]==2) else 0)(x) for x in zip(feature_df.index.day,\n",
    "                                                                                           feature_df.index.month)]\n",
    "    feature_df['is_emancipation_day'] = [(lambda x: 1 if (x[0]==15 & x[1]==4) else 0)(x) for x in zip(feature_df.index.day,\n",
    "                                                                                           feature_df.index.month)]\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_region_dict = {\n",
    "    'cluster 1': (1076, 1126, 1127, 1128, 1129, 1132, 1180, 1181, 1230, 1231, 1232, 1233, 1234, 1282,\n",
    " 1283, 1339, 1383, 1431, 1684, 1734, 2069, 2119),\n",
    "    'cluster 2': (1075, 1125, 1221, 1227, 1272, 1326, 1331, 1382, 1434, 1441, 1480, 1482, 1483, 1530,\n",
    " 1532, 1533, 1580, 1630, 1733, 1783, 2068, 2118, 2168),\n",
    "    'cluster 3': (1173, 1174, 1175, 1176, 1183, 1225, 1278, 1388, 1389, 1390, 1436, 1437, 1438, 1439,\n",
    " 1442),\n",
    "    'cluster 4': (1130, 1131, 1172, 1177, 1178, 1179, 1222, 1223, 1224, 1228, 1229, 1273, 1274, 1279,\n",
    " 1327, 1376, 1377, 1378, 1380, 1426),\n",
    "    'cluster 5': (1077, 1182, 1184, 1235, 1280, 1281, 1284, 1285, 1286, 1287, 1332, 1333, 1334, 1335,\n",
    " 1336, 1337, 1338, 1384, 1385, 1386, 1387, 1435)\n",
    "}\n",
    "best_params_dict = {\n",
    "    'cluster 1': (2, 7, 2, 1),\n",
    "    'cluster 2': (2, 2, 2, 2),\n",
    "    'cluster 3': (2, 2, 2, 0),\n",
    "    'cluster 4': (2, 2, 2, 2),\n",
    "    'cluster 5': (1, 2, 2, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_may(trips_by_regions_may, cluster):\n",
    "    trips_by_regions_may = np.transpose(trips_by_regions_may[trips_by_regions_may['region'].isin(cluster_region_dict[cluster])].drop(['west', 'east', 'south', 'north', 'region'], axis=1))\n",
    "    trips_by_regions_may.columns = [i+1 for i in list(trips_by_regions_may.columns)]\n",
    "    trips_by_regions_may = trips_by_regions_may.set_index(pd.date_range('05/01/2016', periods=int(trips_by_regions_may.shape[0]), freq='H'))\n",
    "    return trips_by_regions_may"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_by_regions_may = pd.read_csv('trips_by_regions_may.csv')\n",
    "\n",
    "trips_by_regions_may_cluster_0 = normalize_data_may(trips_by_regions_may, 'cluster 1')\n",
    "trips_by_regions_may_cluster_1 = normalize_data_may(trips_by_regions_may, 'cluster 2')\n",
    "trips_by_regions_may_cluster_2 = normalize_data_may(trips_by_regions_may, 'cluster 3')\n",
    "trips_by_regions_may_cluster_3 = normalize_data_may(trips_by_regions_may, 'cluster 4')\n",
    "trips_by_regions_may_cluster_4 = normalize_data_may(trips_by_regions_may, 'cluster 5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0.columns = [int(i) for i in data_0.columns]\n",
    "data_1.columns = [int(i) for i in data_1.columns]\n",
    "data_2.columns = [int(i) for i in data_2.columns]\n",
    "data_3.columns = [int(i) for i in data_3.columns]\n",
    "data_4.columns = [int(i) for i in data_4.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = pd.concat([data_0, trips_by_regions_may_cluster_0])\n",
    "data_1 = pd.concat([data_1, trips_by_regions_may_cluster_1])\n",
    "data_2 = pd.concat([data_2, trips_by_regions_may_cluster_2])\n",
    "data_3 = pd.concat([data_3, trips_by_regions_may_cluster_3])\n",
    "data_4 = pd.concat([data_4, trips_by_regions_may_cluster_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1076</th>\n",
       "      <th>1126</th>\n",
       "      <th>1127</th>\n",
       "      <th>1128</th>\n",
       "      <th>1129</th>\n",
       "      <th>1132</th>\n",
       "      <th>1180</th>\n",
       "      <th>1181</th>\n",
       "      <th>1230</th>\n",
       "      <th>1231</th>\n",
       "      <th>...</th>\n",
       "      <th>1234</th>\n",
       "      <th>1282</th>\n",
       "      <th>1283</th>\n",
       "      <th>1339</th>\n",
       "      <th>1383</th>\n",
       "      <th>1431</th>\n",
       "      <th>1684</th>\n",
       "      <th>1734</th>\n",
       "      <th>2069</th>\n",
       "      <th>2119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1273.0</td>\n",
       "      <td>...</td>\n",
       "      <td>664.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>91.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>...</td>\n",
       "      <td>567.0</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 02:00:00</th>\n",
       "      <td>90.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>962.0</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>...</td>\n",
       "      <td>705.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:00:00</th>\n",
       "      <td>32.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>...</td>\n",
       "      <td>615.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 04:00:00</th>\n",
       "      <td>24.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>...</td>\n",
       "      <td>379.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1076   1126   1127   1128   1129   1132   1180   1181  \\\n",
       "2016-01-01 00:00:00  80.0   77.0  319.0  402.0  531.0  267.0  759.0  930.0   \n",
       "2016-01-01 01:00:00  91.0  134.0  404.0  420.0  370.0  224.0  518.0  671.0   \n",
       "2016-01-01 02:00:00  90.0  110.0  393.0  425.0  313.0  138.0  401.0  503.0   \n",
       "2016-01-01 03:00:00  32.0   62.0  252.0  399.0  324.0  166.0  391.0  523.0   \n",
       "2016-01-01 04:00:00  24.0   53.0  145.0  254.0  264.0  145.0  388.0  381.0   \n",
       "\n",
       "                       1230    1231  ...    1234    1282    1283  1339  1383  \\\n",
       "2016-01-01 00:00:00  1001.0  1273.0  ...   664.0   768.0  1076.0  84.0  22.0   \n",
       "2016-01-01 01:00:00  1116.0  1514.0  ...   567.0  1062.0  1178.0  81.0  15.0   \n",
       "2016-01-01 02:00:00   962.0  1363.0  ...   705.0  1060.0  1053.0  63.0  10.0   \n",
       "2016-01-01 03:00:00   968.0  1202.0  ...   615.0   614.0   610.0  44.0   5.0   \n",
       "2016-01-01 04:00:00   646.0   647.0  ...   379.0   319.0   401.0  18.0   4.0   \n",
       "\n",
       "                     1431  1684  1734  2069  2119  \n",
       "2016-01-01 00:00:00   5.0   2.0   2.0  41.0  70.0  \n",
       "2016-01-01 01:00:00   5.0   1.0   5.0   4.0  47.0  \n",
       "2016-01-01 02:00:00   4.0   0.0   3.0   0.0  69.0  \n",
       "2016-01-01 03:00:00   5.0   0.0   2.0   1.0  21.0  \n",
       "2016-01-01 04:00:00   5.0   1.0   0.0   0.0  26.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_q(real, predict):\n",
    "    q = []\n",
    "    for i,j in zip(real, predict):\n",
    "        q.append(abs(i - j))\n",
    "    return np.mean(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_final = []\n",
    "clusters = {'cluster 1': data_0, \n",
    "            'cluster 2': data_1,\n",
    "            'cluster 3': data_2,\n",
    "            'cluster 4': data_3,\n",
    "            'cluster 5': data_4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# May predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time_range = [i for i in list(pd.date_range('05/01/2016', periods=int(24*31), freq='H'))]\n",
    "d, D = 0, 1\n",
    "for cluster_name, data_cluster in clusters.items():\n",
    "    param = best_params_dict[cluster_name]\n",
    "    regressor = LinearRegression()\n",
    "    Qs = []\n",
    "    for series in data_cluster.columns:\n",
    "        features = make_regressive_features(data_cluster[series])\n",
    "        regressor.fit(features.fillna(0), data_cluster[series])\n",
    "        data = pd.DataFrame(data_cluster[series])\n",
    "        data['reg_predictions'] = regressor.predict(features.fillna(0))\n",
    "        data['residuals'] = data[series] - data['reg_predictions']\n",
    "        data['pred'] = np.nan\n",
    "        try:\n",
    "            model_res = sm.tsa.statespace.SARIMAX(data['residuals'][:time_range[0]], \n",
    "                                                 order=(param[0], d, param[1]), \n",
    "                                                 seasonal_order=(param[2], D, param[3], 24)).fit(disp=-1)\n",
    "            model_fitted = sm.tsa.statespace.SARIMAX(data['residuals'],order=(param[0], d, param[1]), \n",
    "                                                 seasonal_order=(param[2], D, param[3], 24)).filter(model_res.params)\n",
    "        except:\n",
    "            continue\n",
    "        Q = []\n",
    "        for time in time_range[:-6]:\n",
    "            predicted_residuals = model_fitted.predict(time, time+6, dynamic=True)\n",
    "            data['pred'][time: time+6] = predicted_residuals + data['reg_predictions'][time: time+6]\n",
    "            Q.append(count_q(data['pred'][time: time+6], data[series][time: time+6]))\n",
    "#             if time.hour == 0:\n",
    "#                 print(time.day)\n",
    "        Qs.append(np.mean(Q))\n",
    "        print('{} series finihshed ({})'.format(series, cluster_name))\n",
    "    Q_final.append(np.mean(Qs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q = 20.65831844879667\n"
     ]
    }
   ],
   "source": [
    "print('Q = {}'.format(np.mean(Q_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# June predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_june(trips_by_regions_june, cluster):\n",
    "    trips_by_regions_june = np.transpose(trips_by_regions_june[trips_by_regions_june['region'].isin(cluster_region_dict[cluster])].drop(['west', 'east', 'south', 'north', 'region'], axis=1))\n",
    "    trips_by_regions_june.columns = [i+1 for i in list(trips_by_regions_june.columns)]\n",
    "    trips_by_regions_june = trips_by_regions_june.set_index(pd.date_range('06/01/2016', periods=int(trips_by_regions_june.shape[0]), freq='H'))\n",
    "    return trips_by_regions_june"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_by_regions_june = pd.read_csv('trips_by_regions_june.csv')\n",
    "\n",
    "trips_by_regions_june_cluster_0 = normalize_data_june(trips_by_regions_june, 'cluster 1')\n",
    "trips_by_regions_june_cluster_1 = normalize_data_june(trips_by_regions_june, 'cluster 2')\n",
    "trips_by_regions_june_cluster_2 = normalize_data_june(trips_by_regions_june, 'cluster 3')\n",
    "trips_by_regions_june_cluster_3 = normalize_data_june(trips_by_regions_june, 'cluster 4')\n",
    "trips_by_regions_june_cluster_4 = normalize_data_june(trips_by_regions_june, 'cluster 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0_final = pd.concat([data_0, trips_by_regions_june_cluster_0])\n",
    "data_1_final = pd.concat([data_1, trips_by_regions_june_cluster_1])\n",
    "data_2_final = pd.concat([data_2, trips_by_regions_june_cluster_2])\n",
    "data_3_final = pd.concat([data_3, trips_by_regions_june_cluster_3])\n",
    "data_4_final = pd.concat([data_4, trips_by_regions_june_cluster_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {'cluster 1': data_0_final, \n",
    "            'cluster 2': data_1_final,\n",
    "            'cluster 3': data_2_final,\n",
    "            'cluster 4': data_3_final,\n",
    "            'cluster 5': data_4_final}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time_range = [i for i in list(pd.date_range('05/31/2016 23:00:00', periods=int(24*30), freq='H'))]\n",
    "result = pd.DataFrame(columns=('id', 'y'))\n",
    "a=0\n",
    "d, D = 0, 1\n",
    "for cluster_name, data_cluster in clusters.items():\n",
    "    param = best_params_dict[cluster_name]\n",
    "    regressor = LinearRegression()\n",
    "    for series in data_cluster.columns:\n",
    "        features = make_regressive_features(data_cluster[series])\n",
    "        regressor.fit(features.fillna(0), data_cluster[series])\n",
    "        data = pd.DataFrame(data_cluster[series])\n",
    "        data['reg_predictions'] = regressor.predict(features.fillna(0))\n",
    "        data['residuals'] = data[series] - data['reg_predictions']\n",
    "        data['pred'] = np.nan\n",
    "        try:\n",
    "            model_res = sm.tsa.statespace.SARIMAX(data['residuals'][:time_range[0]], \n",
    "                                                 order=(param[0], d, param[1]), \n",
    "                                                 seasonal_order=(param[2], D, param[3], 24)).fit(disp=-1)\n",
    "            model_fitted = sm.tsa.statespace.SARIMAX(data['residuals'],order=(param[0], d, param[1]), \n",
    "                                                 seasonal_order=(param[2], D, param[3], 24)).filter(model_res.params)\n",
    "        except:\n",
    "            pass\n",
    "        for time in time_range[:-5]:\n",
    "            predicted_residuals = model_fitted.predict(time+1, time+6, dynamic=True)\n",
    "            data['pred'][time+1: time+6] = predicted_residuals + data['reg_predictions'][time+1: time+6]\n",
    "            for i in range(6):\n",
    "                result = result.append([{'id' : '{}_{}-{}-{}_{}_{}'.format(series, time.year, time.month, time.day, time.hour, i+1),\n",
    "                               'y':data['pred'][time + i +1]}])\n",
    "        print('{} done'.format(series))\n",
    "    print('{} done'.format(cluster_name))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing to a valid format form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids = []\n",
    "for i in result['id'].values:\n",
    "    if i[10]=='5':\n",
    "        new_ids.append(i.replace('-5-', '-05-'))\n",
    "    else:\n",
    "        new_ids.append(i.replace('-6-', '-06-'))\n",
    "result['id'] = new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids = []\n",
    "v = ['-1_', '-2_', '-3_', '-4_', '-5_', '-6_', '-7_', '-8_', '-9_']\n",
    "v_ = ['-01_', '-02_', '-03_', '-04_', '-05_', '-06_', '-07_', '-08_', '-09_']\n",
    "for i in result['id'].values:\n",
    "    target = i[12:15]\n",
    "    if target in v:\n",
    "        new_ids.append(i.replace(target, v_[v.index(target)]))\n",
    "    else:\n",
    "        new_ids.append(i)\n",
    "result['id'] = new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1076_2016-05-31_23_1</td>\n",
       "      <td>48.155182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1076_2016-05-31_23_2</td>\n",
       "      <td>28.972377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1076_2016-05-31_23_3</td>\n",
       "      <td>20.879477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076_2016-05-31_23_4</td>\n",
       "      <td>16.067401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1076_2016-05-31_23_5</td>\n",
       "      <td>14.525768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id          y\n",
       "0  1076_2016-05-31_23_1  48.155182\n",
       "1  1076_2016-05-31_23_2  28.972377\n",
       "2  1076_2016-05-31_23_3  20.879477\n",
       "3  1076_2016-05-31_23_4  16.067401\n",
       "4  1076_2016-05-31_23_5  14.525768"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(437580, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result_arima_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle link: https://www.kaggle.com/c/yellowtaxi/leaderboard (87th place, 31.11283 (Svyatoslav Oreshin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
